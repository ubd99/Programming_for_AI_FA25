{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ubd99/Programming_for_AI_FA25/blob/main/Lab_8_Machine_Learning_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Machine Learning Implementation\n",
        "\n",
        "*   Traditional Implementation\n",
        "*   Sklearn Pipeline Implementation"
      ],
      "metadata": {
        "id": "2asgKb4RCry3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Traditional Machine Learning Implementation**"
      ],
      "metadata": {
        "id": "FbORs_SNsdZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "titanic_data = pd.read_csv('titanic.csv')\n",
        "\n",
        "#print(titanic_data.isnull().sum())\n",
        "# Handle missing values\n",
        "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace=True)\n",
        "titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "#sex = pd.get_dummies(train['Sex'],dtype=int)\n",
        "titanic_data = pd.get_dummies(titanic_data, columns=['Sex', 'Embarked'], dtype=int)\n",
        "\n",
        "# Select features and target variable\n",
        "#X = titanic_data[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S']]\n",
        "X = titanic_data.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "y = titanic_data[['Survived']]\n",
        "print(X)\n",
        "print(y)\n",
        "\n",
        "# Step 4: Split the Data into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 6: Train the KNN Model\n",
        "knn = KNeighborsClassifier(n_neighbors=5)  # You can tune n_neighbors\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Step 7: Make Predictions\n",
        "y_pred = knn.predict(X_test)\n",
        "#print(\"Predicted Values:\")\n",
        "#print(y_pred )\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Step 8: Evaluate the Model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "5h_b1vtSbXw-",
        "outputId": "362439bf-2404-4b87-dfb8-2d9c8a1bc6a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Age'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Age'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3552341017.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#print(titanic_data.isnull().sum())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Handle missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtitanic_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitanic_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtitanic_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Embarked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitanic_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Embarked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Age'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sklearn Pipeline Implementation**"
      ],
      "metadata": {
        "id": "0v6QLYCxh2mZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('titanic.csv')\n",
        "\n",
        "#print(\"Original DataFrame:\")\n",
        "#print(data)\n",
        "#print(data.shape)\n",
        "\n",
        "\n",
        "def impute_embarked(X):\n",
        "    X['Embarked'] = X['Embarked'].fillna(X['Embarked'].mode()[0])  # Fill missing values\n",
        "    return X\n",
        "\n",
        "# Custom function to create the FamilySize feature\n",
        "def create_family_size(X):\n",
        "    X['FamilySize'] = X['SibSp'] + X['Parch'] + 1  # Adding 1 for the individual themselves\n",
        "    return X\n",
        "\n",
        "# Custom function to drop specified columns\n",
        "def drop_columns(X):\n",
        "    return X.drop(['SibSp', 'Parch'], axis=1)\n",
        "\n",
        "# Function to create FamilySize and drop SibSp and Parch columns\n",
        "def family_size(X):\n",
        "    X = create_family_size(X)\n",
        "    X = drop_columns(X)\n",
        "    return X\n",
        "\n",
        "# Create pipelines for Age\n",
        "age_pipeline = Pipeline(steps=[\n",
        "    ('age_imputer', SimpleImputer(strategy='mean')),  # Impute Age\n",
        "    ('age_scaler', MinMaxScaler())  # Scale Age\n",
        "])\n",
        "\n",
        "fare_pipeline = Pipeline(steps=[\n",
        "    #('fare_imputer', SimpleImputer(strategy='mean')),  # Impute Fare\n",
        "    ('fare_scaler', MinMaxScaler())  # Scale Fare\n",
        "])\n",
        "\n",
        "family_size_pipeline = Pipeline(steps=[\n",
        "    ('family_size_creator', FunctionTransformer(family_size)),\n",
        "    ('family_size_scaler', MinMaxScaler()),  # Scale Family_Size\n",
        "])\n",
        "\n",
        "embarked_pipeline = Pipeline(steps=[\n",
        "    ('embarked_imputer', FunctionTransformer(impute_embarked)),  # Impute Embarked\n",
        "    ('embarked_onehot', OneHotEncoder())  # One-hot encode Embarked\n",
        "])\n",
        "\n",
        "# Create a ColumnTransformer to preprocess the data\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('age_encoder', age_pipeline, ['Age']),\n",
        "    ('fare_encoder', fare_pipeline, ['Fare']),\n",
        "    ('family_size', family_size_pipeline, ['SibSp', 'Parch']),  # Process FamilySize\n",
        "    ('embarked_encoder', embarked_pipeline, ['Embarked']),\n",
        "    ('sex_encoder', OneHotEncoder(), ['Sex']),\n",
        "    ('Pclass_scaler', MinMaxScaler(), ['Pclass']),  # Scale Pclass\n",
        "], remainder='passthrough')\n",
        "\n",
        "# Create a complete pipeline that includes preprocessing and the classifier\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),  # Preprocessing steps\n",
        "    ('classifier', KNeighborsClassifier(n_neighbors=5))  # KNN Classifier\n",
        "])\n",
        "\n",
        "X = data.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "y = data['Survived']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "print(type(X_train))\n",
        "print(type(y_train))\n",
        "print(type(X_test))\n",
        "print(type(y_test))\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(\"Predicted Values:\")\n",
        "print(y_pred)\n",
        "print(y_pred.shape)\n",
        "print(type(y_pred))\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Step 8: Evaluate the Model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2FbXPYah0pj",
        "outputId": "5e2f6991-3b08-477b-b55c-5a0de6df92d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n",
            "331       1    male  45.5      0      0   28.5000        S\n",
            "733       2    male  23.0      0      0   13.0000        S\n",
            "382       3    male  32.0      0      0    7.9250        S\n",
            "704       3    male  26.0      1      0    7.8542        S\n",
            "813       3  female   6.0      4      2   31.2750        S\n",
            "..      ...     ...   ...    ...    ...       ...      ...\n",
            "106       3  female  21.0      0      0    7.6500        S\n",
            "270       1    male   NaN      0      0   31.0000        S\n",
            "860       3    male  41.0      2      0   14.1083        S\n",
            "435       1  female  14.0      1      2  120.0000        S\n",
            "102       1    male  21.0      0      1   77.2875        S\n",
            "\n",
            "[712 rows x 7 columns]\n",
            "331    0\n",
            "733    0\n",
            "382    0\n",
            "704    0\n",
            "813    0\n",
            "      ..\n",
            "106    1\n",
            "270    0\n",
            "860    0\n",
            "435    1\n",
            "102    0\n",
            "Name: Survived, Length: 712, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "Predicted Values:\n",
            "[0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
            " 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1\n",
            " 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1\n",
            " 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0\n",
            " 1 0 0 0 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1]\n",
            "(179,)\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "Model Accuracy: 0.80\n",
            "Confusion Matrix:\n",
            "[[90 15]\n",
            " [21 53]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('titanic.csv')\n",
        "\n",
        "#print(\"Original DataFrame:\")\n",
        "#print(data)\n",
        "#print(data.shape)\n",
        "\n",
        "def impute_embarked(X):\n",
        "    X['Embarked'] = X['Embarked'].fillna(X['Embarked'].mode()[0])  # Fill missing values\n",
        "    return X\n",
        "\n",
        "# Custom function to create the FamilySize feature\n",
        "def create_family_size(X):\n",
        "    X['FamilySize'] = X['SibSp'] + X['Parch'] + 1  # Adding 1 for the individual themselves\n",
        "    return X\n",
        "\n",
        "# Custom function to drop specified columns\n",
        "def drop_columns(X):\n",
        "    return X.drop(['SibSp', 'Parch'], axis=1)\n",
        "\n",
        "# Function to create FamilySize and drop SibSp and Parch columns\n",
        "def family_size(X):\n",
        "    X = create_family_size(X)\n",
        "    print(X)\n",
        "    X = drop_columns(X)\n",
        "    print(X)\n",
        "    return X\n",
        "\n",
        "\n",
        "# Create pipelines for Age\n",
        "age_pipeline = Pipeline(steps=[\n",
        "    ('age_imputer', SimpleImputer(strategy='mean')),  # Impute Age\n",
        "    ('age_scaler', MinMaxScaler())  # Scale Age\n",
        "])\n",
        "\n",
        "fare_pipeline = Pipeline(steps=[\n",
        "    #('fare_imputer', SimpleImputer(strategy='mean')),  # Impute Fare\n",
        "    ('fare_scaler', MinMaxScaler())  # Scale Fare\n",
        "])\n",
        "\n",
        "family_size_pipeline = Pipeline(steps=[\n",
        "    ('family_size_creator', FunctionTransformer(family_size)),\n",
        "    ('family_size_scaler', MinMaxScaler()),  # Scale Family_Size\n",
        "])\n",
        "\n",
        "embarked_pipeline = Pipeline(steps=[\n",
        "    ('embarked_imputer', FunctionTransformer(impute_embarked)),  # Impute Embarked\n",
        "    ('embarked_onehot', OneHotEncoder())  # One-hot encode Embarked\n",
        "])\n",
        "\n",
        "# Create a ColumnTransformer to preprocess the data\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('age_encoder', age_pipeline, ['Age']),\n",
        "    ('fare_encoder', fare_pipeline, ['Fare']),\n",
        "    ('family_size', family_size_pipeline, ['SibSp', 'Parch']),  # Process FamilySize\n",
        "    ('embarked_encoder', embarked_pipeline, ['Embarked']),\n",
        "    ('sex_encoder', OneHotEncoder(), ['Sex']),\n",
        "    ('Pclass_scaler', MinMaxScaler(), ['Pclass']),  # Scale Pclass\n",
        "], remainder='passthrough')\n",
        "\n",
        "# Create a complete pipeline that includes preprocessing and the classifier\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),  # Preprocessing steps\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # RandomForest Classifier\n",
        "])\n",
        "\n",
        "X = data.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "y = data['Survived']\n",
        "print('-----------------')\n",
        "print(X)\n",
        "print(y)\n",
        "print('-----------------')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "print(type(X_train))\n",
        "print(type(y_train))\n",
        "print(type(X_test))\n",
        "print(type(y_test))\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(\"Predicted Values:\")\n",
        "print(y_pred)\n",
        "print(y_pred.shape)\n",
        "print(type(y_pred))\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Step 8: Evaluate the Model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQKQyHMiIh4y",
        "outputId": "64fec96a-6c42-4c30-b288-f7a24a543378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n",
            "     Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
            "0         3    male  22.0      1      0   7.2500        S\n",
            "1         1  female  38.0      1      0  71.2833        C\n",
            "2         3  female  26.0      0      0   7.9250        S\n",
            "3         1  female  35.0      1      0  53.1000        S\n",
            "4         3    male  35.0      0      0   8.0500        S\n",
            "..      ...     ...   ...    ...    ...      ...      ...\n",
            "886       2    male  27.0      0      0  13.0000        S\n",
            "887       1  female  19.0      0      0  30.0000        S\n",
            "888       3  female   NaN      1      2  23.4500        S\n",
            "889       1    male  26.0      0      0  30.0000        C\n",
            "890       3    male  32.0      0      0   7.7500        Q\n",
            "\n",
            "[891 rows x 7 columns]\n",
            "0      0\n",
            "1      1\n",
            "2      1\n",
            "3      1\n",
            "4      0\n",
            "      ..\n",
            "886    0\n",
            "887    1\n",
            "888    0\n",
            "889    1\n",
            "890    0\n",
            "Name: Survived, Length: 891, dtype: int64\n",
            "-----------------\n",
            "     Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n",
            "331       1    male  45.5      0      0   28.5000        S\n",
            "733       2    male  23.0      0      0   13.0000        S\n",
            "382       3    male  32.0      0      0    7.9250        S\n",
            "704       3    male  26.0      1      0    7.8542        S\n",
            "813       3  female   6.0      4      2   31.2750        S\n",
            "..      ...     ...   ...    ...    ...       ...      ...\n",
            "106       3  female  21.0      0      0    7.6500        S\n",
            "270       1    male   NaN      0      0   31.0000        S\n",
            "860       3    male  41.0      2      0   14.1083        S\n",
            "435       1  female  14.0      1      2  120.0000        S\n",
            "102       1    male  21.0      0      1   77.2875        S\n",
            "\n",
            "[712 rows x 7 columns]\n",
            "331    0\n",
            "733    0\n",
            "382    0\n",
            "704    0\n",
            "813    0\n",
            "      ..\n",
            "106    1\n",
            "270    0\n",
            "860    0\n",
            "435    1\n",
            "102    0\n",
            "Name: Survived, Length: 712, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "     SibSp  Parch  FamilySize\n",
            "331      0      0           1\n",
            "733      0      0           1\n",
            "382      0      0           1\n",
            "704      1      0           2\n",
            "813      4      2           7\n",
            "..     ...    ...         ...\n",
            "106      0      0           1\n",
            "270      0      0           1\n",
            "860      2      0           3\n",
            "435      1      2           4\n",
            "102      0      1           2\n",
            "\n",
            "[712 rows x 3 columns]\n",
            "     FamilySize\n",
            "331           1\n",
            "733           1\n",
            "382           1\n",
            "704           2\n",
            "813           7\n",
            "..          ...\n",
            "106           1\n",
            "270           1\n",
            "860           3\n",
            "435           4\n",
            "102           2\n",
            "\n",
            "[712 rows x 1 columns]\n",
            "     SibSp  Parch  FamilySize\n",
            "709      1      1           3\n",
            "439      0      0           1\n",
            "840      0      0           1\n",
            "720      0      1           2\n",
            "39       1      0           2\n",
            "..     ...    ...         ...\n",
            "433      0      0           1\n",
            "773      0      0           1\n",
            "25       1      5           7\n",
            "84       0      0           1\n",
            "10       1      1           3\n",
            "\n",
            "[179 rows x 3 columns]\n",
            "     FamilySize\n",
            "709           3\n",
            "439           1\n",
            "840           1\n",
            "720           2\n",
            "39            2\n",
            "..          ...\n",
            "433           1\n",
            "773           1\n",
            "25            7\n",
            "84            1\n",
            "10            3\n",
            "\n",
            "[179 rows x 1 columns]\n",
            "Predicted Values:\n",
            "[0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
            " 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1\n",
            " 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1\n",
            " 0 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1\n",
            " 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1]\n",
            "(179,)\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "Model Accuracy: 0.82\n",
            "Confusion Matrix:\n",
            "[[91 14]\n",
            " [19 55]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Task\n",
        "\n",
        "*  Extend the traditional implemenetation by including the EDA steps performed in the Sklearn Pipeline implementation.\n",
        "*  Analyse the output of the EDA steps performed using the Sklearn Preprocessing and Pipeline functions and investigate whether there are any logical errors or not.\n",
        "*  Apply cross-valiadation using 5-folds and display both fold wise and overall accuracy.\n",
        "*  Perform the steps mentioned above on the following dataset\n",
        "\n",
        "https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease"
      ],
      "metadata": {
        "id": "Vu7nZz_DrFFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "titanic_data = pd.read_csv('titanic.csv')\n",
        "\n",
        "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace=True)\n",
        "titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "X = titanic_data.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "y = titanic_data[['Survived']]\n",
        "\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "ct = ColumnTransformer([\n",
        "    ('scale', StandardScaler(), numeric_cols),\n",
        "    ('encode', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "])\n",
        "\n",
        "X_transformed = ct.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_transformed, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy)\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "Uvb1C9ICJ6DA",
        "outputId": "8892fd0f-72f4-4453-deda-57cd160438f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7988826815642458\n",
            "[[91 14]\n",
            " [22 52]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1576551248.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace=True)\n",
            "/tmp/ipython-input-1576551248.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode()[0], inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ]
    }
  ]
}